{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "report.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1zPuL1C2FN8",
        "colab_type": "text"
      },
      "source": [
        "# **THEORY QUESTIONS**\n",
        "\n",
        "###**k-Nearest Neighbor Classification**\n",
        "\n",
        "--------------------------\n",
        "\n",
        "A1. k-Nearest Neighbor algorithm doesn't learn anything by training. To predict values in testing, distance between every instance should be calculated and this can be costly and take too much time.\n",
        "\n",
        "--------------------------\n",
        "\n",
        "A2. X-Y-X-Y-X-Y-X-Y-X-Y-X-Y-X-Y\n",
        "\n",
        "In a 1 dimensional dataset like this, predictions will always be false for 1-NN because nearest instances will always be the from the other class for every instance.\n",
        "\n",
        "--------------------------\n",
        "\n",
        "\n",
        "A3.\n",
        "\n",
        "\n",
        "*   Class appointed to the test instance for k=1 would be negative. Because closest instance to the test instance is a negative one above it.\n",
        "*   Class appointed to the test instance for k=3 would be negative. Because 3 closest instance to the test instance is are two negative above it and one positive instance below it. Since there is more negative instance, result will be negative.\n",
        "*   Class appointed to the test instance for k=5 would be positive. Because 5 closest instance to the test instance is are two negative above it and three positive instance below it. Since there is more positive instance, result will be positive.\n",
        "\n",
        "\n",
        "\n",
        "--------------------------\n",
        "\n",
        "A4.\n",
        "\n",
        "\n",
        "*   True\n",
        "*   True\n",
        "*   True\n",
        "\n",
        "\n",
        "\n",
        "###**Linear Regression**\n",
        "\n",
        "--------------------------\n",
        "\n",
        "A1. ( (2025 - (7569+4900+8464+4489+2025)) / 5 )  /  (8464-2025)  =  -0,538\n",
        "\n",
        "--------------------------\n",
        "\n",
        "A2.\n",
        "\n",
        "--------------------------\n",
        "\n",
        "\n",
        "A3.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "--------------------------\n",
        "\n",
        "A4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WIO8yXWD5LW",
        "colab_type": "text"
      },
      "source": [
        "#**REPORT**\n",
        "\n",
        "###**Overview of the Problem**\n",
        "\n",
        "In this assignment, we're required to build a machine learning algorithm that can be used in a movie recommendation system. In order to achieve that, we're going to work use k-Nearest Neighbor algorithm. \n",
        "\n",
        "The program will be given 4 csv files. movies.csv which have movieId, movie \n",
        "\n",
        "*   movies.csv which has columns for movie's ID, movie's title, and genre.\n",
        "*   tags.csv which has columns user's ID, movie's ID, tag which the user used for movie and timestamp\n",
        "*   links.csv which has columns movie's ID on our system, movie's ID on Internet Movie Database and, movie's ID on The Movie Database\n",
        "*   ratings_train.csv which has columns user's ID, movie's ID, rating the user given to the movie and timestamp \n",
        "\n",
        "\n",
        "The algorithm I created will make a prediction on what would be rating a user gives to a particular movie which he/she haven't watched yet. Algorithm will use other users' rating on that movie who have similiar movie tastes.\n",
        "\n",
        "###**My Solution**\n",
        "\n",
        "\n",
        "1.   I read given csv files and split the file that has ratings into 2 parts after shuffeling it. Tha part which has %80 of the file will be used for training and the other part will be used for testing.\n",
        "2.   Since a dataframe which makes accesing different users ratings for different movies easier would be useful, I create that dataframe using movies.csv and user ratings from training part of ratings_train.csv. While doing so, I create a dictionary that stores information of which users watched watched that movie for every single movie. That dictonaries usage will be explained later.\n",
        "3.   The program will predict ratings based on k-Nearest Neighbor algorithm. I will select nearest neighbor to a user using cosine similarity. Highest similarity means nearest neighbor. Since every box in dataframe for ratings should be filled with values to calculate cosine similarities, empty boxes are filled with 0's. This solution has a very low cost and doesn't have a large negative effect on results. \n",
        "4.   I calculate and store similarities between every user on dataframe named userUserMatrix. After that, I declare k and start predicting ratings using k-NN.\n",
        "5.   The program does predictions for test data row by row. For every row, first it gets the userId and movieId. Feeding getWatchedNeighbours algorithm with userId and movieId, a list that has closest k neighbors to the user who watched that particular movie. Dictionary mentioned above is used to speed up this process.\n",
        "6.   After getting closest neighbors, prediction process startes. There is two option k-NN and weighted k-NN. Using formulas below, ratings are predicted. Absolute value of difference between the prediction and the real rating is calculated. This value is error on that prediction. This operation is done for every row in test data and average error is calculated. That is called mean absolute error(MAE).\n",
        "\n",
        "      $  ($$\\sum\\limits_{i=1}^{k} r_i $$ )    /k $  --> Formula for k-NN\n",
        "\n",
        "      $  ($$\\sum\\limits_{i=1}^{k} r_i*s_i $$ )    /    ($$\\sum\\limits_{i=1}^{k} s_i $$ )  $  --> Formula for weighted k-NN\n",
        "\n",
        "      $ r_i $ is rating for that neighbour\n",
        "\n",
        "      $ s_i $ is similarity for that neighbour\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##**Analysis of the Results**\n",
        "\n",
        "\n",
        "###First Approach\n",
        "When I first begun developing, the program was selecting closest neighbors without paying attention to the fact that if that user watched the movie we're predicting the rating for. Using that method, MAE's and runtimes are below for different k values:\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "\n",
        "Overall MAE is :  2.459  when using  2 - NN\n",
        "\n",
        "Overall MAE is :  2.457  when using weighted  2 - NN\n",
        "\n",
        "Runtime:  0:00:10.09\n",
        "\n",
        "--------------\n",
        "\n",
        "Overall MAE is :  2.444  when using  3 - NN\n",
        "\n",
        "Overall MAE is :  2.442  when using weighted  3 - NN\n",
        "\n",
        "Runtime:  0:00:11.82\n",
        "\n",
        "--------------\n",
        "\n",
        "Overall MAE is :  2.444  when using  4 - NN\n",
        "\n",
        "Overall MAE is :  2.440  when using weighted  4 - NN\n",
        "\n",
        "Runtime:  0:00:13.33\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  2.440  when using  5 - NN\n",
        "\n",
        "Overall MAE is :  2.437  when using weighted  5 - NN\n",
        "\n",
        "Runtime:  0:00:15.03\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  2.452  when using  6 - NN\n",
        "\n",
        "Overall MAE is :  2.448  when using weighted  6 - NN\n",
        "\n",
        "Runtime:  0:00:16.46\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  2.467  when using  7 - NN\n",
        "\n",
        "Overall MAE is :  2.462  when using weighted  7 - NN\n",
        "\n",
        "Runtime:  0:00:18.34\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  2.473  when using  8 - NN\n",
        "\n",
        "Overall MAE is :  2.468  when using weighted  8 - NN\n",
        "\n",
        "Runtime:  0:00:19.89\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  2.495  when using  10 - NN\n",
        "\n",
        "Overall MAE is :  2.488  when using weighted  10 - NN\n",
        "\n",
        "Runtime:  0:00:23.01\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  2.529  when using  15 - NN\n",
        "\n",
        "Overall MAE is :  2.521  when using weighted  15 - NN\n",
        "\n",
        "Runtime:  0:00:30.54\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  2.563  when using  20 - NN\n",
        "\n",
        "Overall MAE is :  2.553  when using weighted  20 - NN\n",
        "\n",
        "Runtime:  0:00:38.87\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  2.610  when using  30 - NN\n",
        "\n",
        "Overall MAE is :  2.597  when using weighted  30 - NN\n",
        "\n",
        "Runtime:  0:00:54.64\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  2.694  when using  50 - NN\n",
        "\n",
        "Overall MAE is :  2.674  when using weighted  50 - NN\n",
        "\n",
        "Runtime:  0:01:27.53\n",
        "\n",
        "--------------\n",
        "\n",
        "###Second Approach\n",
        "I observed that mean absolute errors are really high. The reason behind that is when some closest neighbours didn't rate that particular movie, their ratings are taken as 0 to prevent errors and this lowers predictions too much. In order to prevent that, I took a different approach. I choose neighbors who watched that movie. For example when k=5, instead of choosing 5 closest neighbors to the user, first I get a list which stores usersId's of users who watched to movie and choose closest 5 between them. Results were like below using that approach:\n",
        "\n",
        "--------------\n",
        "\n",
        "Overall MAE is :  0.977  when using  2 - NN\n",
        "\n",
        "Overall MAE is :  0.980  when using weighted  2 - NN\n",
        "\n",
        "Runtime:  0:00:22.28\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.949  when using  3 - NN\n",
        "\n",
        "Overall MAE is :  0.950  when using weighted  3 - NN\n",
        "\n",
        "Runtime:  0:00:22.88\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.934  when using  4 - NN\n",
        "\n",
        "Overall MAE is :  0.935  when using weighted  4 - NN\n",
        "\n",
        "Runtime:  0:00:23.86\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.923  when using  5 - NN\n",
        "\n",
        "Overall MAE is :  0.924  when using weighted  5 - NN\n",
        "\n",
        "Runtime:  0:00:24.93\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.919  when using  6 - NN\n",
        "\n",
        "Overall MAE is :  0.919  when using weighted  6 - NN\n",
        "\n",
        "Runtime:  0:00:26.48\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.913  when using  7 - NN\n",
        "\n",
        "Overall MAE is :  0.913  when using weighted  7 - NN\n",
        "\n",
        "Runtime:  0:00:27.60\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.909  when using  8 - NN\n",
        "\n",
        "Overall MAE is :  0.909  when using weighted  8 - NN\n",
        "\n",
        "Runtime:  0:00:28.68\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.906  when using  10 - NN\n",
        "\n",
        "Overall MAE is :  0.905  when using weighted  10 - NN\n",
        "\n",
        "Runtime:  0:00:30.13\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.901  when using  15 - NN\n",
        "\n",
        "Overall MAE is :  0.900  when using weighted  15 - NN\n",
        "\n",
        "Runtime:  0:00:33.68\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.902  when using  20 - NN\n",
        "\n",
        "Overall MAE is :  0.899  when using weighted  20 - NN\n",
        "\n",
        "Runtime:  0:00:36.96\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.903  when using  30 - NN\n",
        "\n",
        "Overall MAE is :  0.899  when using weighted  30 - NN\n",
        "\n",
        "\n",
        "Runtime:  0:00:43.01\n",
        "\n",
        "--------------\n",
        "\n",
        "\n",
        "Overall MAE is :  0.904  when using  50 - NN\n",
        "\n",
        "Overall MAE is :  0.899  when using weighted  50 - NN\n",
        "\n",
        "Runtime:  0:00:51.36\n",
        "\n",
        "--------------\n",
        "\n",
        "As we can see, second approach affects the results pretty well.  After k=15, the improvement in results slowed down and runtime keep scaling up. So in my program is built for k=15.\n",
        "\n",
        "One odd thing in the results are that weighted k-NN doesn't improves the results as expected, sometimes it has even higher MAE's. I believe this could be due to the fact that since most similarity values are pretty low even for closest neighbors, the difference between the effects of first and fifth closest neighbors is too low. By incrementing k value, difference between first and last nearest neighbor used in calculation raises and weighted k-NN start to getting better results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLvkAEKn3q45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "bad4a75e-dc44-45a2-d194-502ffa574124"
      },
      "source": [
        "\"\"\"At this part of the code, I import required libraries, read given files and split \n",
        "ratings_train.csv into 2 parts as train&test\n",
        "\n",
        "moviesCsv: csv file that has information about movies which has columns for movie's ID, \n",
        "movie's title, and genre.\n",
        "\n",
        "ratingsTrainCsv and ratingsTestCsv: csv files that has information about ratings given to \n",
        "movies.\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import operator\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "moviesCsv = pd.read_csv(\"movies.csv\", error_bad_lines = False, encoding = 'latin', delimiter= \",\")\n",
        "ratingsCsv = pd.read_csv(\"ratings_train.csv\", error_bad_lines = False, encoding = 'latin', delimiter= \",\")\n",
        "ratingsCsv = ratingsCsv.sample(frac=1).reset_index(drop=True)\n",
        "splitIndex =int(len(ratingsCsv)*8/10)\n",
        "splitIndex\n",
        "ratingsTrainCsv = ratingsCsv.iloc[ :splitIndex,]\n",
        "ratingsTestCsv = ratingsCsv.iloc[splitIndex:,]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-acb34188dbb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmoviesCsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content/drive/My Drive/ml2019assg1/movies.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'latin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mratingsCsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content/drive/My Drive/ml2019assg1/ratings_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'latin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mratingsCsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratingsCsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'content/drive/My Drive/ml2019assg1/movies.csv' does not exist: b'content/drive/My Drive/ml2019assg1/movies.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-1CyRYDGwwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"At this part, a dataframe which stores ratings from training data is created. Empty cells \n",
        "in that dataframe is filled with 0's. Also a dictionary containing information of users who \n",
        "watched a particular movie is created. \n",
        "\n",
        "userMovieMatrix: A pandas dataframe that columns are named with userId's and rows are named \n",
        "with movieId's. Intersection point between a userId and movieId stores value of that specific \n",
        "user's given rating to that particular movie\n",
        "\n",
        "usersWatchedMovie: A dictionary that key's are movieIds and values are arrays containing userId's \n",
        "of users who watched that movie. has columns user's ID, movie's ID, rating the user given to the \n",
        "movie and timestamp\"\"\"\n",
        "\n",
        "userMovieMatrix = pd.DataFrame(columns = range(1,611), index = moviesCsv['movieId'], dtype=object)\n",
        "usersWatchedMovie = {}\n",
        "for i in moviesCsv['movieId']:\n",
        "  usersWatchedMovie[i] = list()\n",
        "for i in range(len(ratingsTrainCsv)):\n",
        "    line = ratingsTrainCsv.iloc[i]\n",
        "    userMovieMatrix.loc[line['movieId']][line['userId']] = line['rating']\n",
        "    usersWatchedMovie[line['movieId']].append(line['userId'])\n",
        "userMovieMatrix.fillna(0, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9x2b6WPZZL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"This function returns k nearest neighbors of userId who watched movie with movieId.\n",
        "\n",
        "Returned array will consist of k objects which are arrays. Those array will consist of 2 objects, \n",
        "first one is that neighbor's similarity with userId, second one is that neighbor's userId\"\"\"\n",
        "\n",
        "def getWatchedNeighbours(movieId, userId, k):\n",
        "    similarityInfos = userUserMatrix.loc[:, userId]\n",
        "    similarityList = []\n",
        "    for i in usersWatchedMovie[movieId]:\n",
        "        similarityList.append((similarityInfos.loc[i], i))\n",
        "    similarityList.sort(key=operator.itemgetter(0), reverse=True)\n",
        "    neighboursList = []\n",
        "    for i in range(k):\n",
        "        if (i >= len(similarityList)):\n",
        "          break\n",
        "        neighboursList.append(similarityList[i])\n",
        "    return neighboursList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW-2lmOl7-Ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"At this part, predictions are calculated for every rating that is stored in test data and errors\n",
        "of predictions are calculated. Average error rate of every rating in that data is calculated and printed.\n",
        "\n",
        "In this part, program gets movieId and userId information from test data. Calculates predictions using k-NN\n",
        "and weighted k-NN. After doing this operation for every row in test data, errors for every row is summed up \n",
        "and divided to row number to recieve MAE.\n",
        "\n",
        "knnVariable: k value for k-Nearest Neighbor algorithm. This can be changed to optimize the program\"\"\"\n",
        "\n",
        "knnVariable = 15\n",
        "\n",
        "totalError = 0\n",
        "weightedTotalError = 0\n",
        "for y in range(len(ratingsTestCsv)):\n",
        "    line = ratingsTestCsv.iloc[y]\n",
        "    neighboursList = getWatchedNeighbours(line['movieId'], line['userId'], knnVariable)\n",
        "    totalPrediction = 0\n",
        "    weightedTotalPrediction = 0\n",
        "    totalSimilarity = 0\n",
        "    for j in neighboursList:\n",
        "         neighbourRating = (userMovieMatrix.loc[:,j[1]]).loc[line['movieId']]\n",
        "         totalPrediction = totalPrediction + neighbourRating\n",
        "         weightedTotalPrediction = weightedTotalPrediction + (neighbourRating*j[0])\n",
        "         totalSimilarity += j[0]\n",
        "    if not (len(neighboursList) == 0):\n",
        "      totalPrediction = totalPrediction / len(neighboursList)\n",
        "    if (totalSimilarity != 0):\n",
        "      weightedTotalPrediction = weightedTotalPrediction / totalSimilarity\n",
        "    totalError += abs(totalPrediction - line['rating'])\n",
        "    weightedTotalError += abs(weightedTotalPrediction - line['rating'])\n",
        "\n",
        "print (\"\\nOverall MAE is : \", totalError / len(ratingsTestCsv), \" when using \", knnVariable, \"- NN\")\n",
        "print (\"Overall MAE is : \", weightedTotalError / len(ratingsTestCsv), \" when using weighted \", knnVariable, \"- NN\")\n",
        "print(\"Runtime: \", datetime.now()-start)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}